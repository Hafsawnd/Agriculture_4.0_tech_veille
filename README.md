ğŸŒ¾ Veille Agricole 4.0 â€“ Plateforme de Web Scraping et Tableau de Bord Interactif

Ce projet met en place un systÃ¨me automatisÃ© pour collecter, analyser et visualiser des contenus liÃ©s Ã  lâ€™Agriculture 4.0. Il sâ€™appuie sur plusieurs web scrapers personnalisÃ©s, une base de donnÃ©es MongoDB et un tableau de bord interactif dÃ©veloppÃ© avec Streamlit. Les donnÃ©es collectÃ©es sont Ã©valuÃ©es en termes de crÃ©dibilitÃ© avant dâ€™Ãªtre affichÃ©es.
ğŸ“ Architecture du Projet
.
â”œâ”€â”€ scrape_google_alert.py                   # Fetches Google Alerts via Gmail API
â”œâ”€â”€ scrape_google_scholar.py                 # Queries Google Scholar via SerpAPI
â”œâ”€â”€ scrape_ieee.py                           # Scrapes IEEE Xplore articles
â”œâ”€â”€ scrape_springer.py                       # Scrapes SpringerLink
â”œâ”€â”€ scrape_wiley.py                          # Scrapes Wiley Online Library
â”œâ”€â”€ scrape_talkwalker/
â”‚   â”œâ”€â”€ auto_save_to_talkwalkerfolder.py     # Saves Talkwalker emails via IMAP
â”‚   â””â”€â”€ extract_informations_from_talkwalker.py  # Extracts articles from saved Talkwalker
â”œâ”€â”€ credibility_test.py                      # Filters out non-credible publications
â”œâ”€â”€ app.py                                   # Streamlit dashboard for data visualization
â”œâ”€â”€ daily_scraper_scheduler.py               # Central scheduler for daily automation
â”œâ”€â”€ requirements.txt                         # Clean dependency list
â”œâ”€â”€ .env                                     # Secret config (excluded)
â”œâ”€â”€ .gitignore                               # Git exclusion rules
â”œâ”€â”€ token.json                               # Gmail token (excluded)
â””â”€â”€ README.md                                # This file


âš™ï¸ Instructions dâ€™Installation
1. Installation des dÃ©pendances
pip install -r requirements.txt

2. Configuration des accÃ¨s confidentiels

CrÃ©er un fichier .env Ã  la racine :

GMAIL_TOKEN_PATH=token.json
GMAIL_CREDENTIALS_PATH=client_secret_XXXX.json
SERPAPI_KEY=your-serpapi-key
IMAP_EMAIL=youremail@example.com
IMAP_PASSWORD=your-imap-password


Le fichier .env reste protÃ©gÃ© grÃ¢ce au .gitignore.

ğŸš€ Extraction & Traitement AutomatisÃ©s
Lancer les scrapers individuellement :
python scrape_google_alert.py
python scrape_google_scholar.py
python scrape_ieee.py
python scrape_springer.py
python scrape_wiley.py
python scrape_talkwalker/auto_save_to_talkwalkerfolder.py
python scrape_talkwalker/extract_informations_from_talkwalker.py

Planification quotidienne :
python daily_scraper_scheduler.py

Application du filtre de crÃ©dibilitÃ© :
python credibility_test.py

ğŸ“Š Tableau de Bord Streamlit

Lancement du dashboard :

streamlit run app.py


Il permet dâ€™explorer :

ğŸ“ˆ Les tendances globales & lâ€™Ã©volution des publications

ğŸŒ Une cartographie des sources

ğŸ“° Les contenus rÃ©cents et pertinents

ğŸ” Les domaines scientifiques les plus actifs

â˜ï¸ Des word clouds informatifs

ğŸ“… Des sÃ©ries temporelles des publications

![dash1](https://github.com/user-attachments/assets/9fc5fabe-5107-4f7a-a5b2-667bb6b429d4)

![dash2](https://github.com/user-attachments/assets/c09ddcb0-2e80-4d5a-8b0e-4c2cbc7d864e)
![dash3](https://github.com/user-attachments/assets/d38da935-996b-43b6-a647-2ab15e30c04f)
ğŸ“¦ Collections MongoDB

google_alerts_Agriculture4.0

talkwalker_alerts_Agriculture4.0

ieee_agriculture_4_0_newest / relevant

wiley_agriculture_4_0_newest / relevant

springer_agriculture_4_0_newest / relevant

scholar_agriculture_4_0_newest / relevant

ğŸ§  FonctionnalitÃ©s Principales

âœ… Scraping automatisÃ© avec comportement anti-bot
âœ… Gestion sÃ©curisÃ©e des identifiants
âœ… ExÃ©cution planifiÃ©e quotidienne
âœ… DÃ©duplication intelligente dans MongoDB
âœ… Score de crÃ©dibilitÃ© pour filtrage avancÃ©
âœ… Dashboard Streamlit riche Voici une **version propre, concise et professionnelle**, parfaitement adaptÃ©e pour un **README GitHub**.
Elle est structurÃ©e, claire, sans emojis (ou avec quelques-uns si tu veux), et optimisÃ©e pour GitHub.

---

# ğŸŒ¾ Veille Agricole 4.0 â€“ Web Scraping & Streamlit Dashboard

Ce projet propose une solution complÃ¨te de veille technologique sur **lâ€™Agriculture 4.0**, intÃ©grant du web scraping automatisÃ©, un filtrage de crÃ©dibilitÃ© des sources, une base de donnÃ©es MongoDB et un tableau de bord interactif construit avec **Streamlit**.
Lâ€™objectif est de collecter, analyser et visualiser des articles scientifiques, alertes et contenus pertinents provenant de plusieurs plateformes acadÃ©miques.

---

## ğŸ“‚ Structure du Projet

```
.
â”œâ”€â”€ scrape_google_alert.py                   # Extraction des Google Alerts via Gmail API
â”œâ”€â”€ scrape_google_scholar.py                 # RequÃªtes Google Scholar via SerpAPI
â”œâ”€â”€ scrape_ieee.py                           # Scraper IEEE Xplore
â”œâ”€â”€ scrape_springer.py                       # Scraper SpringerLink
â”œâ”€â”€ scrape_wiley.py                          # Scraper Wiley Online Library
â”œâ”€â”€ scrape_talkwalker/
â”‚   â”œâ”€â”€ auto_save_to_talkwalkerfolder.py     # Sauvegarde des emails Talkwalker via IMAP
â”‚   â””â”€â”€ extract_informations_from_talkwalker.py  # Extraction des articles Talkwalker
â”œâ”€â”€ credibility_test.py                      # Score de crÃ©dibilitÃ© des publications
â”œâ”€â”€ app.py                                   # Tableau de bord Streamlit
â”œâ”€â”€ daily_scraper_scheduler.py               # Planification dâ€™exÃ©cution quotidienne
â”œâ”€â”€ requirements.txt                         # DÃ©pendances
â”œâ”€â”€ .env                                     # Variables sensibles (non versionnÃ©)
â”œâ”€â”€ .gitignore                               # RÃ¨gles dâ€™exclusion
â””â”€â”€ README.md                                # Documentation
```

---

## âš™ï¸ Installation

### 1. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

ou manuellement :

```bash
pip install selenium webdriver-manager pymongo schedule requests beautifulsoup4 python-dotenv streamlit
```

---

## ğŸ” Configuration

CrÃ©er un fichier `.env` :

```
GMAIL_TOKEN_PATH=token.json
GMAIL_CREDENTIALS_PATH=client_secret_XXXX.json
SERPAPI_KEY=your-serpapi-key
IMAP_EMAIL=youremail@example.com
IMAP_PASSWORD=your-imap-password
```

> Le fichier `.env` est ignorÃ© par Git.

---

## ğŸš€ ExÃ©cution des Scrapers

### Lancer un scraper spÃ©cifique :

```bash
python scrape_google_alert.py
python scrape_google_scholar.py
python scrape_ieee.py
python scrape_springer.py
python scrape_wiley.py
python scrape_talkwalker/auto_save_to_talkwalkerfolder.py
python scrape_talkwalker/extract_informations_from_talkwalker.py
```

### Lancer lâ€™ensemble des scrapers quotidiennement :

```bash
python daily_scraper_scheduler.py
```

### Appliquer le filtre de crÃ©dibilitÃ© :

```bash
python credibility_test.py
```

---

## ğŸ“Š Tableau de Bord Streamlit

Lancer lâ€™application :

```bash
streamlit run app.py
```

### Le dashboard inclut :

* Ã‰volution et tendances globales
* RÃ©partition gÃ©ographique des sources
* Articles rÃ©cents et pertinents
* Classement des domaines scientifiques
* Word clouds
* SÃ©ries temporelles
![dash1](https://github.com/user-attachments/assets/9fc5fabe-5107-4f7a-a5b2-667bb6b429d4)

![dash2](https://github.com/user-attachments/assets/c09ddcb0-2e80-4d5a-8b0e-4c2cbc7d864e)
![dash3](https://github.com/user-attachments/assets/d38da935-996b-43b6-a647-2ab15e30c04f)
---

## ğŸ—„ï¸ Collections MongoDB

* `google_alerts_Agriculture4.0`
* `talkwalker_alerts_Agriculture4.0`
* `ieee_agriculture_4_0_newest`, `ieee_agriculture_4_0_relevant`
* `wiley_agriculture_4_0_newest`, `wiley_agriculture_4_0_relevant`
* `springer_agriculture_4_0_newest`, `springer_agriculture_4_0_relevant`
* `scholar_agriculture_4_0_newest`, `scholar_agriculture_4_0_relevant`

---

## ğŸ§  FonctionnalitÃ©s

* Scraping automatisÃ©
* Gestion sÃ©curisÃ©e des identifiants
* Planification quotidienne
* DÃ©duplication intelligente
* SystÃ¨me de crÃ©dibilitÃ© des sources
* Dashboard interactif

---

## ğŸ“ Projet AcadÃ©mique

Projet rÃ©alisÃ© dans le cadre dâ€™un module de **Veille Technologique â€“ Agriculture 4.0** par une Ã©quipe dâ€™Ã©tudiants en ingÃ©nierie data.

---



ğŸ“ Projet acadÃ©mique â€“ Veille Technologique Agriculture 4.0

DÃ©veloppÃ© par une Ã©quipe dâ€™Ã©tudiants en ingÃ©nierie data.




